{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ab28ad",
   "metadata": {},
   "source": [
    "## API経由での推論実行環境\n",
    "\n",
    "OpenRouterを使ってAPI経由で推論を実行（無料で出来る範囲で）  \n",
    "\n",
    "使用可能なモデルの一例  \n",
    "`deepseek/deepseek-chat-v3-0324:free` : 685B  \n",
    "`deepseek/deepseek-r1-0528:free` : 671B  \n",
    "`deepseek/deepseek-r1:free` : 671B  \n",
    "`qwen/qwen3-235b-a22b-07-25:free` : 235B  \n",
    "  \n",
    "参考  \n",
    "[【LLMは無料で使え！】OpenRouterのススメ【CLINEにも！】](https://zenn.dev/asap/articles/5cda4576fbe7cb)\n",
    "\n",
    "無料で最大1000request/日まで使えるようですので、予備検討には使えるかと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f342a2",
   "metadata": {},
   "source": [
    "#### 懸念事項\n",
    "\n",
    "APIの使用については不明確な点があります（運営の見解は無料APIはOKとのことですが）\n",
    "本内容は、トレーニングデータの生成ではなく、あくまで予備検討・調査と捉えてください\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5de178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Math, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3248f890",
   "metadata": {},
   "source": [
    "### APT_keyの登録\n",
    "\n",
    "`.env`ファイルを作成して以下のように登録。あるいは、本ファイル内に直接記入しても良い。\n",
    "\n",
    "```\n",
    "OPENROUTER_API_KEY=your_api_key_here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nI0fofz_tUWR",
   "metadata": {
    "id": "nI0fofz_tUWR"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# api_key = \"your_api_key_here\"\n",
    "# api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# base_url = \"https://api.openai.com/v1\"\n",
    "\n",
    "# api_key = \"your_api_key_here\"\n",
    "api_key = os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "base_url = \"https://openrouter.ai/api/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e72b7",
   "metadata": {},
   "source": [
    "### 動作確認\n",
    "\n",
    "openaiの仕様に準じているみたいです。`import openai`が使えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7a98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=api_key, base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531cd5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！ ご用件がありましたら、どんなことでもおっしゃってください。お手伝いできることがあれば幸いです！\n"
     ]
    }
   ],
   "source": [
    "msgs:List[Dict[str, str]] = [\n",
    "    {\"role\": \"system\", \"content\": \"あなたは親切なアシスタントです。\"},\n",
    "    {\"role\": \"user\", \"content\": \"こんにちは！\"},\n",
    "]\n",
    "\n",
    "# GPTのテスト\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-r1:free\",\n",
    "    messages=msgs,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf1d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22543ce5",
   "metadata": {},
   "source": [
    "# 検証\n",
    "\n",
    "PersonaHabに基づいて、対象を明確化した上で問題を作成させる  \n",
    "\n",
    "`proj-persona/PersonaHub` (license: cc-by-nc-sa-4.0)  \n",
    "https://huggingface.co/datasets/proj-persona/PersonaHub  \n",
    "\n",
    "↓\n",
    "\n",
    "hugginfaceのdatasetから、検証用に1つだけサンプルを拝借  \n",
    "\n",
    "persona\n",
    "```text\n",
    "A scientist who specializes in virology and the study of ancient viruses. This persona is interested in the potential dangers of thawing permafrost and the revival of ancient viruses, and is likely to be part of a research team studying the potential impact of these viruses on human and animal health. This persona may also be familiar with the work of Jean-Michel Claverie, the lead author of the study.\n",
    "\n",
    "```\n",
    "\n",
    "> ウイルス学と古代ウイルスの研究を専門とする科学者。このペルソナは、永久凍土の融解と古代ウイルスの復活の潜在的な危険性に関心を持っており、これらのウイルスが人間と動物の健康に及ぼす潜在的な影響を研究する研究チームの一員である可能性が高い。また、この研究の筆頭著者であるジャン＝ミシェル・クラヴェリー氏の研究にも精通している可能性がある。\n",
    "\n",
    "このpersonaベースでを生成\n",
    "\n",
    "\n",
    "今回は  \n",
    "`deepseek/deepseek-r1:free` : 671B  \n",
    "で検証  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e8798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11940fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = (\n",
    "    \"Create a math problem related to the following persona:\\n\\n\"\n",
    "    \"{persona}\\n\\n\"\n",
    "    \"Note:\\n\\n\"\n",
    "    \"1. The math problem should be challenging and involve advanced mathematical skills and knowledge. Only top talents can solve it correctly.\\n\"\n",
    "    \"2. You should make full use of the persona description to create the math problem to ensure that the math problem is unique and specific to the persona.\\n\"\n",
    "    \"3. First, consider **Topics** that require advanced mathematical skills closely related to persona descriptions and list the relevant **Mathematical skills**.\"\n",
    "    \" Then, drawing on your knowledge and experience of persona descriptions, create specialised master's- or doctoral-level problems that combine highly interrelated **Topics** and **Mathematical skills**.\\n\"\n",
    "    \"4. If the math problem contains more than one task, structure it so that each task relates to the others, with the most difficult task being completed last.\\n\"\n",
    "    \"5. The problem must be solved analytically, not numerically.\"\n",
    "    # \" Also, make sure that the conditions required for an analytical solution are included in the problem statement, and that the problem is presented as solvable.\\n\"\n",
    "    \" Also, make sure that the problem statement includes all the conditions necessary for an analytical solution and presents the problem as one that can be uniquely solved.\\n\"\n",
    "    \"6. Your response should always start with 'Math problem:'. Your response should not include a solution to the created math problem.\"\n",
    "    \" Do not include any information, such as 'notes', that is not necessary for solving the question.\\n\\n\"\n",
    "    # \"4. The problem must be solved analytically, not numerically.\"\n",
    "    # \" Also, make sure that the conditions required for an analytical solution are included in the problem statement, and that the problem is presented as solvable.\\n\"\n",
    "    # \"4. Consider the advanced mathematical skills that are highly relevant to the persona description, and create specialised problems at master's or doctoral level that reflect these skills.\"\n",
    "    # \"4. Consider the advanced mathematical skills that are highly relevant to the persona description, and create specialised problems at leading researchers or doctoral-level level that reflect these skills.\\n\\n\"\n",
    "    # \"5. First, consider <topics> that require advanced mathematical skills closely related to persona descriptions and list the relevant <mathematical skills>.\"\n",
    "    # \" Then, drawing on your knowledge and experience of persona descriptions, create specialised master's- or doctoral-level problems that combine highly interrelated <topics> and <mathematical skills>.\\n\"\n",
    "    # \"6. If your problem contains more than one task, structure it so that each task relates to the others, with the most difficult task being completed last.\\n\\n\"\n",
    "    \n",
    "    # \"The following issues should also be avoided when creating the math problem:\\n\"\n",
    "    # \"- Insufficient information: Ploblems may lack the essential details needed to solve them, leaving them incomplete or ambiguous. For example, a trigonometry question might omit the necessary angles or distances.\\n\"\n",
    "    # \"- Unsolvable or computationally intractable problems: Some problems are either unsolvable or require excessive brute-force calculations, which are impractical for evaluating reasoning abilities.\\n\"\n",
    "    # \"- Nonsensical problems: Models sometimes produce problems that are logically inconsistent, confusing or ambiguous, such as a probability issue with unclear parameters or an impossible geometry scenario.\"\n",
    "    # \" Inconsistent, confusing or ambiguous problems, such as a probability issue with unclear parameters or an impossible geometry scenario.\\n\"\n",
    "    # # \"- Deceitful Solutions: Occasionally, models fabricate solutions to nonsensical or unsolvable problems, presenting incorrect logic as plausible reasoning.\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176db801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "265eb4ce",
   "metadata": {},
   "source": [
    "## 5. 適用カテゴリと数学スキルについて自分で深堀りさせる\n",
    "\n",
    "ドメイン（persona）に関連する高度な数学的要素を要求するカテゴリ（topic）を想起させたうえで、具体的な数学スキル（amth_skill）をリストアップし、それらを融合して難化させたい。  \n",
    "↓  \n",
    "R1クラスのモデル  \n",
    "* MATHレベルのデータセットは内部に持ち合わせている\n",
    "* 専門的なカテゴリと数学的スキルの関連性についても同様  \n",
    "  \n",
    "外部から不要な情報を与えて指定することが逆に制約になっていそうなので、カテゴリ（topic）×数学スキル（amth_skill）の組み合わせ検討もお任せしたい。 \n",
    "  \n",
    " `topic`と`math_skill`について、プレースホルダーを使って深堀りし融合させ、問題の幅を広げる試みをする。\n",
    "\n",
    "↓  \n",
    "難易度：    \n",
    "数学スキル: 修士レベル以上  \n",
    "学際性: 疫学、地球科学、確率過程の統合（博士/研究レベル）  \n",
    "ただし、一部修正は必要  \n",
    "taskがに複数に分かれる  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b098740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a math problem related to the following persona:\n",
      "\n",
      "A scientist who specializes in virology and the study of ancient viruses.\n",
      "\n",
      "Note:\n",
      "\n",
      "1. The math problem should be challenging and involve advanced mathematical skills and knowledge. Only top talents can solve it correctly.\n",
      "2. You should make full use of the persona description to create the math problem to ensure that the math problem is unique and specific to the persona.\n",
      "3. First, consider **Topics** that require advanced mathematical skills closely related to persona descriptions and list the relevant **Mathematical Skills**. Then, drawing on your knowledge and experience of persona descriptions, create specialised master's- or doctoral-level problems that combine highly interrelated **Topics** and **Mathematical Skills**.\n",
      "4. If the math problem contains more than one task, structure it so that each task relates to the others, with the most difficult task being completed last.\n",
      "5. The problem must be solved analytically and must not require any numerical calculations. Also, make sure that the problem statement includes all the conditions necessary for an analytical solution and presents the problem as one that can be uniquely solved.\n",
      "6. Your response should always start with 'Math problem:'. Your response should not include a solution to the created math problem. Do not include any information, such as 'notes', that is not necessary for solving the question.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persona_deiscription = \"A scientist who specializes in virology and the study of ancient viruses.\"\n",
    "\n",
    "# # p_seed = {\"subject\": \"computer science\", \"group\": \"artificial intelligence\", \"category\": \"explainable AI\", \"job\": \"AIAI Robotics Researcher\"}\n",
    "# p_seed = {\"subject\": \"engineering\", \"group\": \"biomedical engineering\", \"category\": \"medical imaging\", \"job\": \"Biomechanics Engineer\"}\n",
    "# persona_deiscription = f\"A {p_seed[\"job\"]} who specializes in {p_seed[\"group\"]} and the study of {p_seed['category']}.\"\n",
    "\n",
    "user_prompt = (\n",
    "    \"Create a math problem related to the following persona:\\n\\n\"\n",
    "    \"{persona}\\n\\n\"\n",
    "    \"Note:\\n\\n\"\n",
    "    \"1. The math problem should be challenging and involve advanced mathematical skills and knowledge. Only top talents can solve it correctly.\\n\"\n",
    "    \"2. You should make full use of the persona description to create the math problem to ensure that the math problem is unique and specific to the persona.\\n\"\n",
    "    \"3. First, consider **Topics** that require advanced mathematical skills closely related to persona descriptions and list the relevant **Mathematical Skills**.\"\n",
    "    \" Then, drawing on your knowledge and experience of persona descriptions, create specialised master's- or doctoral-level problems that combine highly interrelated **Topics** and **Mathematical Skills**.\\n\"\n",
    "    \"4. If the math problem contains more than one task, structure it so that each task relates to the others, with the most difficult task being completed last.\\n\"\n",
    "    \"5. The problem must be solved analytically and must not require any numerical calculations.\"\n",
    "    \" Also, make sure that the problem statement includes all the conditions necessary for an analytical solution and presents the problem as one that can be uniquely solved.\\n\"\n",
    "    \"6. Your response should always start with 'Math problem:'. Your response should not include a solution to the created math problem.\"\n",
    "    \" Do not include any information, such as 'notes', that is not necessary for solving the question.\\n\\n\"\n",
    ")\n",
    "print(user_prompt.format(persona=persona_deiscription))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa2520da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle Math problem:  \n",
       "\n",
       "A virologist reconstructs the evolutionary dynamics of an ancient RNA virus using a coalescent model. The viral population is assumed to evolve according to a time-varying effective population size \\( N(t) = N_0 e^{-\\alpha t} \\), where \\( \\alpha > 0 \\), and mutations follow a Poisson process with rate \\( \\theta \\) per lineage per unit time. Observations from *n* contemporary viral strains are used to infer the time since the most recent common ancestor (TMRCA) and mutation rate.  \n",
       "\n",
       "**Tasks**:  \n",
       "1. Let \\( k \\) lineages exist at time \\( t = 0 \\). Derive the probability that at least \\( m \\) lineages (\\( 1 \\leq m \\leq k \\)) survive without coalescing until time \\( T \\), assuming coalescence occurs at rate \\( \\binom{j}{2}/N(t) \\) when there are \\( j \\) lineages.  \n",
       "\n",
       "2. Using the time-varying \\( N(t) \\), show that the expected TMRCA of the *n* strains satisfies the integral equation:  \n",
       "\\[\n",
       "\\mathbb{E}[T_{\\text{MRCA}}] = \\int_{0}^{\\infty} \\left(1 - \\prod_{j=2}^n \\exp\\left(-\\binom{j}{2} \\int_0^t \\frac{1}{N(s)} ds \\right)\\right) dt.\n",
       "\\]  \n",
       "Simplify this expression under \\( N(t) = N_0 e^{-\\alpha t} \\) and prove whether \\( \\mathbb{E}[T_{\\text{MRCA}}] \\) converges as \\( \\alpha \\to 0 \\).  \n",
       "\n",
       "3. Suppose mutations are observed at positions \\( \\{t_1, t_2, \\dots, t_k\\} \\) along a reconstructed phylogenetic tree with branch lengths proportional to time. Construct the likelihood function \\( \\mathcal{L}(\\theta) \\) for the mutation rate \\( \\theta \\), and prove that its maximum likelihood estimator (MLE) satisfies  \n",
       "\\[\n",
       "\\hat{\\theta} = \\frac{k}{\\int_0^{T_{\\text{MRCA}}} L(t) dt},\n",
       "\\]  \n",
       "where \\( L(t) \\) is the total branch length of the tree at time \\( t \\). State all assumptions required for this result.$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' 問題の生成 '''\n",
    "\n",
    "msgs:List[Dict[str, str]] = [\n",
    "    {\"role\": \"user\", \"content\": user_prompt.format(persona=persona_deiscription)},\n",
    "]\n",
    "\n",
    "client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    # model=\"deepseek/deepseek-r1-0528:free\",\n",
    "    model=\"deepseek/deepseek-r1:free\",\n",
    "    messages=msgs,\n",
    ")\n",
    "generated_problem = response.choices[0].message.content\n",
    "Math(generated_problem)\n",
    "# print(generated_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a286127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Math problem:  \\n\\nA virologist reconstructs the evolutionary dynamics of an ancient RNA virus using a coalescent model. The viral population is assumed to evolve according to a time-varying effective population size \\\\( N(t) = N_0 e^{-\\\\alpha t} \\\\), where \\\\( \\\\alpha > 0 \\\\), and mutations follow a Poisson process with rate \\\\( \\\\theta \\\\) per lineage per unit time. Observations from *n* contemporary viral strains are used to infer the time since the most recent common ancestor (TMRCA) and mutation rate.  \\n\\n**Tasks**:  \\n1. Let \\\\( k \\\\) lineages exist at time \\\\( t = 0 \\\\). Derive the probability that at least \\\\( m \\\\) lineages (\\\\( 1 \\\\leq m \\\\leq k \\\\)) survive without coalescing until time \\\\( T \\\\), assuming coalescence occurs at rate \\\\( \\\\binom{j}{2}/N(t) \\\\) when there are \\\\( j \\\\) lineages.  \\n\\n2. Using the time-varying \\\\( N(t) \\\\), show that the expected TMRCA of the *n* strains satisfies the integral equation:  \\n\\\\[\\n\\\\mathbb{E}[T_{\\\\text{MRCA}}] = \\\\int_{0}^{\\\\infty} \\\\left(1 - \\\\prod_{j=2}^n \\\\exp\\\\left(-\\\\binom{j}{2} \\\\int_0^t \\\\frac{1}{N(s)} ds \\\\right)\\\\right) dt.\\n\\\\]  \\nSimplify this expression under \\\\( N(t) = N_0 e^{-\\\\alpha t} \\\\) and prove whether \\\\( \\\\mathbb{E}[T_{\\\\text{MRCA}}] \\\\) converges as \\\\( \\\\alpha \\\\to 0 \\\\).  \\n\\n3. Suppose mutations are observed at positions \\\\( \\\\{t_1, t_2, \\\\dots, t_k\\\\} \\\\) along a reconstructed phylogenetic tree with branch lengths proportional to time. Construct the likelihood function \\\\( \\\\mathcal{L}(\\\\theta) \\\\) for the mutation rate \\\\( \\\\theta \\\\), and prove that its maximum likelihood estimator (MLE) satisfies  \\n\\\\[\\n\\\\hat{\\\\theta} = \\\\frac{k}{\\\\int_0^{T_{\\\\text{MRCA}}} L(t) dt},\\n\\\\]  \\nwhere \\\\( L(t) \\\\) is the total branch length of the tree at time \\\\( t \\\\). State all assumptions required for this result.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3706b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fa81751",
   "metadata": {},
   "source": [
    "### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c80f3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = (\n",
    "    \"以下の問題は高度な専門性を要求する数学の問題です、回答可能な数学の問題として成立しているでしょうか。また、この問題を解くために必要な数学的要求スキルとそれ以外の専門的な知識レベル（学部、修士、博士、学際レベルなど）について日本語で解説してください\\n\\n\"\n",
    "    \"{problem}\\n\\n\"\n",
    ")\n",
    "\n",
    "# print(user_prompt.format(problem=generated_problem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1a90873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "この問題は高度な数学的専門性を必要とするものですが、以下のように各タスクに分けて考えることができます。\n",
       "\n",
       "**タスク1**  \n",
       "**問題の成立性**：  \n",
       "確かに成立しています。時間変化する有効集団サイズ \\( N(t) \\) のもとで、合流モデルにおける系統の生存確率を導出する問題です。非定常ポアソン過程と合流速度の積分計算を組み合わせる必要があり、確率過程の理論に基づいて厳密に解くことが可能です。\n",
       "\n",
       "**必要なスキル**：  \n",
       "- **数学**：非斉時ポアソン過程、積分変換、組合せ確率の計算。  \n",
       "- **専門知識**：合流理論の基礎と時間変化する集団サイズの扱い。  \n",
       "- **レベル**：博士課程レベル（確率論と集団遺伝学の融合領域）。\n",
       "\n",
       "---\n",
       "\n",
       "**タスク2**  \n",
       "**問題の成立性**：  \n",
       "与えられた積分方程式の導出と簡略化は、合流理論の延長線上で解決可能です。ただし、\\( \\alpha \\to 0 \\) の挙動を解析する際に定常状態（定数集団サイズ）との整合性を確認する必要があります。\n",
       "\n",
       "**導出の流れ**：  \n",
       "1. 合流事象の生起を時間変換 \\( \\tau(t) = \\int_0^t \\frac{1}{N(s)}ds \\) を用いて標準合流過程にマッピング。  \n",
       "2. 無矛盾性確認：積分方程式が期待値 \\( \\mathbb{E}[T_{\\text{MRCA}}] \\) を正確に表現することを示す。  \n",
       "3. \\( N(t) = N_0 e^{-\\alpha t} \\) の場合、時間積分を解析的に評価し、\\( \\alpha \\to 0 \\) で古典的な定数集団サイズモデルの結果と一致することを示す。\n",
       "\n",
       "**必要なスキル**：  \n",
       "- **数学**：積分変換、漸近解析、微分方程式。  \n",
       "- **専門知識**：時間変化集団サイズ下でのTMRCAの期待値計算。  \n",
       "- **レベル**：修士〜博士課程レベル（確率微分方程式の応用）。\n",
       "\n",
       "---\n",
       "\n",
       "**タスク3**  \n",
       "**問題の成立性**：  \n",
       "突然変異プロセスの尤度関数の構築は標準的です。ポアソン過程の性質と分岐時間の積分を用いてMLEを導出可能です。\n",
       "\n",
       "**導出の流れ**：  \n",
       "1. 再構築された系統樹の分岐長 \\( L(t) \\) に沿った突然変異の生起をポアソン過程としてモデル化。  \n",
       "2. 尤度関数 \\( \\mathcal{L}(\\theta) \\) を書き、最尤推定量 \\( \\hat{\\theta} = \\frac{k}{\\int_0^{T_{\\text{MRCA}}} L(t)dt} \\) を導出。  \n",
       "3. 前提条件（無限サイト仮定、中立進化、分岐長の正確性）を明示。\n",
       "\n",
       "**必要なスキル**：  \n",
       "- **数学**：ポアソン過程の尤度関数、最尤推定。  \n",
       "- **専門知識**：系統樹解析と分子進化モデル。  \n",
       "- **レベル**：学部上級〜修士課程レベル（生物統計学の基礎）。\n",
       "\n",
       "---\n",
       "\n",
       "**総合的な専門性の評価**：  \n",
       "- **数学的要求**：確率論（非斉時ポアソン過程、積分方程式）、統計学（最尤推定）、微分積分。  \n",
       "- **分野知識**：集団遺伝学の合流理論、系統進化モデル、ウイルス進化の動態。  \n",
       "- **必要な教育レベル**：タスク1〜2は博士課程、タスク3は修士課程レベル。学際的な問題のため、数学と生物学の両方の深い理解が必要です。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "''' 生成した問題の評価 '''\n",
    "msgs:List[Dict[str, str]] = [\n",
    "    {\"role\": \"user\", \"content\": user_prompt.format(problem=generated_problem)},\n",
    "]\n",
    "\n",
    "client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-r1:free\",\n",
    "    messages=msgs,\n",
    ")\n",
    "assessment_result = response.choices[0].message.content\n",
    "Markdown(assessment_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9ebe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e12f95d",
   "metadata": {},
   "source": [
    "### 修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "739daac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve the following problems and confirm whether they can be answered analytically as mathematical problems.\n",
      "Math problem:  \n",
      "\n",
      "A virologist reconstructs the evolutionary dynamics of an ancient RNA virus using a coalescent model. The viral population is assumed to evolve according to a time-varying effective population size \\( N(t) = N_0 e^{-\\alpha t} \\), where \\( \\alpha > 0 \\), and mutations follow a Poisson process with rate \\( \\theta \\) per lineage per unit time. Observations from *n* contemporary viral strains are used to infer the time since the most recent common ancestor (TMRCA) and mutation rate.  \n",
      "\n",
      "**Tasks**:  \n",
      "1. Let \\( k \\) lineages exist at time \\( t = 0 \\). Derive the probability that at least \\( m \\) lineages (\\( 1 \\leq m \\leq k \\)) survive without coalescing until time \\( T \\), assuming coalescence occurs at rate \\( \\binom{j}{2}/N(t) \\) when there are \\( j \\) lineages.  \n",
      "\n",
      "2. Using the time-varying \\( N(t) \\), show that the expected TMRCA of the *n* strains satisfies the integral equation:  \n",
      "\\[\n",
      "\\mathbb{E}[T_{\\text{MRCA}}] = \\int_{0}^{\\infty} \\left(1 - \\prod_{j=2}^n \\exp\\left(-\\binom{j}{2} \\int_0^t \\frac{1}{N(s)} ds \\right)\\right) dt.\n",
      "\\]  \n",
      "Simplify this expression under \\( N(t) = N_0 e^{-\\alpha t} \\) and prove whether \\( \\mathbb{E}[T_{\\text{MRCA}}] \\) converges as \\( \\alpha \\to 0 \\).  \n",
      "\n",
      "3. Suppose mutations are observed at positions \\( \\{t_1, t_2, \\dots, t_k\\} \\) along a reconstructed phylogenetic tree with branch lengths proportional to time. Construct the likelihood function \\( \\mathcal{L}(\\theta) \\) for the mutation rate \\( \\theta \\), and prove that its maximum likelihood estimator (MLE) satisfies  \n",
      "\\[\n",
      "\\hat{\\theta} = \\frac{k}{\\int_0^{T_{\\text{MRCA}}} L(t) dt},\n",
      "\\]  \n",
      "where \\( L(t) \\) is the total branch length of the tree at time \\( t \\). State all assumptions required for this result.\n",
      "\n",
      "- The problem must be solved analytically and must not require any numerical calculations.If there are any deficiencies in the problem, such as insufficient conditions, revise the problem statement so that a unique answer can be obtained analytically, without the need for numerical calculation. Then, create a **Revised Problem**. Also, explain the revisions: output the **Revised Points**.\n",
      "- If you have revised the question, please submit your answer to the revised question as your **Final Answer**. If you have not revised the question, please submit your answer to the original question as your **Final Answer**.\n",
      "- Make sure only the answer in the **Final Answer** enclosed in the latex style. If there are multiple answers, please list them as **Final Answer** in the form of [Answer 1, Answer 2, ...].\n",
      "- Please provide in the following format. Do not include any other text.\n",
      "json format:\n",
      "{\"revised_problem\": \"**Revised Problem**\", \"revise_point\": \"**Revised Points**\", \"answer\": \"**Final Answer**\"}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = (\n",
    "    \"Solve the following problems and confirm whether they can be answered analytically as mathematical problems.\\n\"\n",
    "    \"{problem}\\n\\n\"\n",
    "    \"- The problem must be solved analytically and must not require any numerical calculations.\"\n",
    "    \"If there are any deficiencies in the problem, such as insufficient conditions, revise the problem statement\"\n",
    "    \" so that a unique answer can be obtained analytically, without the need for numerical calculation. Then, create a **Revised Problem**.\"\n",
    "    # \"- If there are deficiencies in the problem, such as insufficient conditions, revise the problem statement\"\n",
    "    # \" so that a unique answer can be obtained analytically, and create a **Revised Problem**.\"\n",
    "    \" Also, explain the revisions: output the **Revised Points**.\\n\"\n",
    "    \"- If you have revised the question, please submit your answer to the revised question as your **Final Answer**.\"\n",
    "    \" If you have not revised the question, please submit your answer to the original question as your **Final Answer**.\\n\"\n",
    "    # \"- Please store only the answer in the **Final Answer** and do not include any unnecessary tags or explanations.\"\n",
    "    \"- Make sure only the answer in the **Final Answer** enclosed in the latex style.\"\n",
    "    \" If there are multiple answers, please list them as **Final Answer** in the form of [Answer 1, Answer 2, ...].\\n\"\n",
    "    # \" If there are multiple numerical answers, write them as a comma separated list (n1, n2, ...).\\n\"\n",
    "    \"- Please provide in the following format. Do not include any other text.\\n\"\n",
    "    \"json format:\\n\"\n",
    "    '{{\"revised_problem\": \"**Revised Problem**\", \"revise_point\": \"**Revised Points**\", \"answer\": \"**Final Answer**\"}}'\n",
    ")\n",
    "\n",
    "print(user_prompt.format(problem=generated_problem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "915a877a",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1291 column 1 (char 7095)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m msgs:List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt\u001b[38;5;241m.\u001b[39mformat(problem\u001b[38;5;241m=\u001b[39mgenerated_problem)},\n\u001b[1;32m      3\u001b[0m ]\n\u001b[1;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(api_key\u001b[38;5;241m=\u001b[39mapi_key, base_url\u001b[38;5;241m=\u001b[39mbase_url)\n\u001b[0;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeepseek/deepseek-r1:free\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m assessment_result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     12\u001b[0m Markdown(assessment_result)\n",
      "File \u001b[0;32m~/poe_env/py310_vllm/.venv/lib/python3.10/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/poe_env/py310_vllm/.venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1087\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1085\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1086\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/poe_env/py310_vllm/.venv/lib/python3.10/site-packages/openai/_base_client.py:1256\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1244\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1253\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1254\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1255\u001b[0m     )\n\u001b[0;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/poe_env/py310_vllm/.venv/lib/python3.10/site-packages/openai/_base_client.py:1049\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/poe_env/py310_vllm/.venv/lib/python3.10/site-packages/openai/_base_client.py:1138\u001b[0m, in \u001b[0;36mSyncAPIClient._process_response\u001b[0;34m(self, cast_to, options, response, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(response\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(RAW_RESPONSE_HEADER)):\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, api_response)\n\u001b[0;32m-> 1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/poe_env/py310_vllm/.venv/lib/python3.10/site-packages/openai/_response.py:323\u001b[0m, in \u001b[0;36mAPIResponse.parse\u001b[0;34m(self, to)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_sse_stream:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 323\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_given(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mpost_parser):\n\u001b[1;32m    325\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mpost_parser(parsed)\n",
      "File \u001b[0;32m~/poe_env/py310_vllm/.venv/lib/python3.10/site-packages/openai/_response.py:265\u001b[0m, in \u001b[0;36mBaseAPIResponse._parse\u001b[0;34m(self, to)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# If the API responds with content that isn't JSON then we just return\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# the (decoded) text without performing any parsing so that you can still\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# handle the response however you need to.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_process_response_data(\n\u001b[1;32m    268\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    269\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    271\u001b[0m )\n",
      "File \u001b[0;32m~/poe_env/py310_vllm/.venv/lib/python3.10/site-packages/httpx/_models.py:832\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjson\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjsonlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1291 column 1 (char 7095)"
     ]
    }
   ],
   "source": [
    "msgs:List[Dict[str, str]] = [\n",
    "    {\"role\": \"user\", \"content\": user_prompt.format(problem=generated_problem)},\n",
    "]\n",
    "\n",
    "client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek/deepseek-r1:free\",\n",
    "    messages=msgs,\n",
    ")\n",
    "assessment_result = response.choices[0].message.content\n",
    "Markdown(assessment_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6460fd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assessment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9ff41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py310-vllm",
   "language": "python",
   "name": "py310_vllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
